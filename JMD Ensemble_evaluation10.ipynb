{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r1NmejTIFPtf"
   },
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from envs1 import OfflineEnv\n",
    "from recommender import DRRAgent\n",
    "\n",
    "STATE_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df=pd.read_csv('./movies.dat')\n",
    "movies_list=movies_df.values.tolist()\n",
    "movies_id_to_movies = {movie[0]: movie[1:] for movie in movies_list}\n",
    "movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)\n",
    "ratings_df=pd.read_csv('./ratings.dat')\n",
    "ratings_df = ratings_df.applymap(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_dict = np.load('./user_dict.npy', allow_pickle=True)\n",
    "users_history_lens = np.load('./users_histroy_len.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유저별로 본 영화들 순서대로 정리\n",
    "users_dict = {user : [] for user in set(ratings_df[\"UserID\"])}\n",
    "users_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>255</td>\n",
       "      <td>4</td>\n",
       "      <td>874724710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259</td>\n",
       "      <td>286</td>\n",
       "      <td>4</td>\n",
       "      <td>874724727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259</td>\n",
       "      <td>298</td>\n",
       "      <td>4</td>\n",
       "      <td>874724754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>259</td>\n",
       "      <td>185</td>\n",
       "      <td>4</td>\n",
       "      <td>874724781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259</td>\n",
       "      <td>173</td>\n",
       "      <td>4</td>\n",
       "      <td>874724843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0     259      255       4  874724710\n",
       "1     259      286       4  874724727\n",
       "2     259      298       4  874724754\n",
       "3     259      185       4  874724781\n",
       "4     259      173       4  874724843"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by time\n",
    "ratings_df = ratings_df.sort_values(by='Timestamp', ascending=True)\n",
    "ratings_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put (movie, rating) pairs in user dictionary\n",
    "# Only movies with a rating of 4 or higher are counted for each user's movie history length.\n",
    "ratings_df_gen = ratings_df.iterrows()\n",
    "users_dict_for_history_len = {user : [] for user in set(ratings_df[\"UserID\"])}\n",
    "for data in ratings_df_gen:\n",
    "    users_dict[data[1]['UserID']].append((data[1]['MovieID'], data[1]['Rating']))\n",
    "    if data[1]['Rating'] >= 1:\n",
    "        users_dict_for_history_len[data[1]['UserID']].append((data[1]['MovieID'], data[1]['Rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Movie history length for each user\n",
    "users_history_lens = [len(users_dict_for_history_len[u]) for u in set(ratings_df[\"UserID\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users_history_lens)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.save(\"./data/user_dict.npy\", users_dict)\n",
    "np.save(\"./data/users_histroy_len.npy\", users_history_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_num = max(ratings_df[\"UserID\"])+1\n",
    "items_num = max(ratings_df[\"MovieID\"])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944 1683\n"
     ]
    }
   ],
   "source": [
    "print(users_num, items_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755 1683\n"
     ]
    }
   ],
   "source": [
    "train_users_num = int(users_num * 0.8)\n",
    "train_items_num = items_num\n",
    "print(train_users_num, train_items_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755 755\n"
     ]
    }
   ],
   "source": [
    "train_users_dict = {k:users_dict[k] for k in range(1, train_users_num+1)}\n",
    "train_users_history_lens = users_history_lens[:train_users_num]\n",
    "print(len(train_users_dict),len(train_users_history_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 1683\n"
     ]
    }
   ],
   "source": [
    "eval_users_num = int(users_num * 0.2)\n",
    "eval_items_num = items_num\n",
    "print(eval_users_num, eval_items_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 188\n"
     ]
    }
   ],
   "source": [
    "eval_users_dict = {k:users_dict[k] for k in range(users_num-eval_users_num, users_num)}\n",
    "eval_users_history_lens = users_history_lens[-eval_users_num:]\n",
    "print(len(eval_users_dict),len(eval_users_history_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(recommender, env, check_movies = False, top_k=False, length = False):\n",
    "\n",
    "    # episodic reward \n",
    "    mean_precision = 0\n",
    "    mean_ndcg = 0\n",
    "\n",
    "  # episodic reward\n",
    "    episode_reward = 0\n",
    "    steps = 0\n",
    "    q_loss1 = 0\n",
    "    q_loss2 = 0\n",
    "    countl = 0\n",
    "    correct_list = []\n",
    "    \n",
    "    # Environment \n",
    "    user_id, items_ids, done = env.reset()\n",
    "\n",
    "    while not done:\n",
    "#         print(\"user_id :\",user_id)\n",
    "        # Observe current state & Find action\n",
    "        ## Embedding\n",
    "        user_eb = recommender.embedding_network.get_layer('user_embedding')(np.array(user_id))\n",
    "        items_eb = recommender.embedding_network.get_layer('movie_embedding')(np.array(items_ids))\n",
    "        ## SRM state \n",
    "        state = recommender.srm_ave([np.expand_dims(user_eb, axis=0), np.expand_dims(items_eb, axis=0)])\n",
    "        ## Action(ranking score) \n",
    "        action1 = recommender.actor.network(state)\n",
    "        action2 = recommender.actor2.network(state)\n",
    "        \n",
    "        action = (action1 + action2)/2\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Item \n",
    "        recommended_item = recommender.recommend_item(action, env.recommended_items, top_k=top_k)\n",
    "\n",
    "        next_items_ids, reward, done, _ = env.step(recommended_item, top_k=top_k)\n",
    "        \n",
    "#         print(\"done :\",done)\n",
    "\n",
    "        if countl < length:\n",
    "            countl += 1\n",
    "#             print(\"countl :\",countl)\n",
    "            correct_list.append(reward)\n",
    "            if done == True and countl == length:\n",
    "                dcg, idcg = calculate_ndcg(correct_list, [1 for _ in range(len(correct_list))])\n",
    "#                 print(\"dcg :\", dcg, \"idcg :\", idcg)\n",
    "                mean_ndcg += dcg/idcg\n",
    "#                 print(\"mean_ndcg :\",mean_ndcg)\n",
    "\n",
    "                #precision\n",
    "                correct_list1 = [1 if r > 0 else 0 for r in correct_list]\n",
    "                correct_num = length-correct_list1.count(0)\n",
    "                mean_precision += correct_num/length\n",
    "                   \n",
    "        items_ids = next_items_ids\n",
    "        episode_reward += reward\n",
    "        steps += 1\n",
    "        \n",
    "    return mean_precision, mean_ndcg, reward\n",
    "\n",
    "def calculate_ndcg(rel, irel):\n",
    "    dcg = 0\n",
    "    idcg = 0\n",
    "    rel = [1 if r>0 else 0 for r in rel]\n",
    "    for i, (r, ir) in enumerate(zip(rel, irel)):\n",
    "        dcg += (r)/np.log2(i+2)\n",
    "        idcg += (ir)/np.log2(i+2)\n",
    "    return dcg, idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 500, reward:8.0, precision@5 : 0.29255319148936176, ndcg@5 : 0.30898528224453\n",
      "Model: 1000, reward:-3.0, precision@5 : 0.23404255319148956, ndcg@5 : 0.23377105726712427\n",
      "Model: 1500, reward:-18.0, precision@5 : 0.3159574468085108, ndcg@5 : 0.34528843731399533\n",
      "Model: 2000, reward:-7.0, precision@5 : 0.29787234042553196, ndcg@5 : 0.31228234423969686\n",
      "Model: 2500, reward:-2.0, precision@5 : 0.29999999999999993, ndcg@5 : 0.31465698796946073\n",
      "Model: 3000, reward:-10.5, precision@5 : 0.2957446808510638, ndcg@5 : 0.30503413627332204\n",
      "Model: 3500, reward:3.0, precision@5 : 0.33191489361702137, ndcg@5 : 0.3429275740398099\n",
      "Model: 4000, reward:-2.5, precision@5 : 0.34148936170212785, ndcg@5 : 0.3619360504247451\n",
      "Model: 4500, reward:7.5, precision@5 : 0.29361702127659584, ndcg@5 : 0.30740030713082767\n",
      "Model: 5000, reward:6.5, precision@5 : 0.30000000000000004, ndcg@5 : 0.3186447822137763\n",
      "Model: 5500, reward:-18.5, precision@5 : 0.296808510638298, ndcg@5 : 0.31707982509204735\n",
      "Model: 6000, reward:0.0, precision@5 : 0.2510638297872341, ndcg@5 : 0.2611706296655829\n",
      "Model: 6500, reward:9.0, precision@5 : 0.2925531914893617, ndcg@5 : 0.3006211489004001\n",
      "Model: 7000, reward:-5.0, precision@5 : 0.2840425531914894, ndcg@5 : 0.3006564914005707\n",
      "Model: 7500, reward:4.5, precision@5 : 0.29361702127659595, ndcg@5 : 0.3026293633672475\n",
      "Model: 8000, reward:-4.5, precision@5 : 0.2680851063829788, ndcg@5 : 0.28273040784353415\n",
      "Model: 8500, reward:4.5, precision@5 : 0.30106382978723406, ndcg@5 : 0.31831107781526374\n",
      "Model: 9000, reward:-6.5, precision@5 : 0.2925531914893617, ndcg@5 : 0.29911295108523417\n",
      "Model: 9500, reward:-1.0, precision@5 : 0.28829787234042564, ndcg@5 : 0.29818113262552903\n",
      "Model: 10000, reward:-12.5, precision@5 : 0.2734042553191489, ndcg@5 : 0.2850720437354392\n",
      "Model: 10500, reward:9.5, precision@5 : 0.273404255319149, ndcg@5 : 0.2812973140889408\n",
      "Model: 11000, reward:-14.0, precision@5 : 0.2361702127659575, ndcg@5 : 0.24578928045705703\n",
      "Model: 11500, reward:-33.0, precision@5 : 0.224468085106383, ndcg@5 : 0.23461962889718316\n",
      "Model: 12000, reward:-7.5, precision@5 : 0.25744680851063817, ndcg@5 : 0.26718251297407164\n",
      "Model: 12500, reward:0.5, precision@5 : 0.2691489361702127, ndcg@5 : 0.28120949828402353\n",
      "Model: 13000, reward:-16.0, precision@5 : 0.26276595744680853, ndcg@5 : 0.2745160182409713\n",
      "Model: 13500, reward:8.5, precision@5 : 0.27978723404255323, ndcg@5 : 0.28869069560363303\n",
      "Model: 14000, reward:8.5, precision@5 : 0.274468085106383, ndcg@5 : 0.28911743034890114\n",
      "Model: 14500, reward:1.5, precision@5 : 0.29680851063829783, ndcg@5 : 0.31391206204787186\n",
      "Model: 15000, reward:5.0, precision@5 : 0.2936170212765958, ndcg@5 : 0.3083900976285509\n",
      "Model: 15500, reward:-8.0, precision@5 : 0.28510638297872337, ndcg@5 : 0.29897853428782134\n",
      "Model: 16000, reward:-14.0, precision@5 : 0.2797872340425532, ndcg@5 : 0.29332363291821717\n",
      "Model: 16500, reward:2.0, precision@5 : 0.2893617021276596, ndcg@5 : 0.3002436786951457\n",
      "Model: 17000, reward:10.5, precision@5 : 0.302127659574468, ndcg@5 : 0.32412847590569144\n",
      "Model: 17500, reward:20.5, precision@5 : 0.2957446808510639, ndcg@5 : 0.30534506487288277\n",
      "Model: 18000, reward:-3.0, precision@5 : 0.27340425531914897, ndcg@5 : 0.2817953286174521\n",
      "Model: 18500, reward:-2.0, precision@5 : 0.28723404255319157, ndcg@5 : 0.3031338027330956\n",
      "Model: 19000, reward:2.5, precision@5 : 0.2734042553191491, ndcg@5 : 0.2897148988435264\n",
      "Model: 19500, reward:-3.0, precision@5 : 0.2744680851063831, ndcg@5 : 0.28867486935401565\n",
      "Model: 20000, reward:1.5, precision@5 : 0.27340425531914897, ndcg@5 : 0.2902404261305604\n"
     ]
    }
   ],
   "source": [
    "sum_precision = 0\n",
    "sum_ndcg = 0\n",
    "sum_reward = 0\n",
    "for i in range(1,41):\n",
    "    sum_precision = 0\n",
    "    sum_ndcg = 0\n",
    "    sum_reward = 0\n",
    "    length_k = 5\n",
    "    for user_id in eval_users_dict.keys():\n",
    "        env = OfflineEnv(eval_users_dict, users_history_lens, movies_id_to_movies, STATE_SIZE, fix_user_id=user_id)\n",
    "        recommender = DRRAgent(env, users_num, items_num, STATE_SIZE)\n",
    "        recommender.actor.build_networks()\n",
    "        recommender.actor2.build_networks()\n",
    "        recommender.critic.build_networks()\n",
    "        recommender.critic2.build_networks()\n",
    "        recommender.load_model(f\"./save_weights/actor_{i*500}_fixed.h5\", \n",
    "                               f\"./save_weights/actor2_{i*500}_fixed.h5\", \n",
    "                               f\"./save_weights/critic_{i*500}_fixed.h5\",\n",
    "                              f\"./save_weights/critic2_{i*500}_fixed.h5\")\n",
    "        precision, ndcg, reward = evaluate(recommender, env, top_k= False, length = length_k)\n",
    "        sum_precision += precision\n",
    "        sum_ndcg += ndcg\n",
    "        sum_reward += reward\n",
    "\n",
    "    print(f'Model: {i*500}, reward:{sum_reward}, precision@{length_k} : {sum_precision/len(eval_users_dict)}, ndcg@{length_k} : {sum_ndcg/len(eval_users_dict)}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model: 500, reward:8.0, precision@5 : 0.29255319148936176, ndcg@5 : 0.30898528224453\n",
    "Model: 1000, reward:-3.0, precision@5 : 0.23404255319148956, ndcg@5 : 0.23377105726712427\n",
    "Model: 1500, reward:-18.0, precision@5 : 0.3159574468085108, ndcg@5 : 0.34528843731399533\n",
    "Model: 2000, reward:-7.0, precision@5 : 0.29787234042553196, ndcg@5 : 0.31228234423969686\n",
    "Model: 2500, reward:-2.0, precision@5 : 0.29999999999999993, ndcg@5 : 0.31465698796946073\n",
    "Model: 3000, reward:-10.5, precision@5 : 0.2957446808510638, ndcg@5 : 0.30503413627332204\n",
    "Model: 3500, reward:3.0, precision@5 : 0.33191489361702137, ndcg@5 : 0.3429275740398099\n",
    "Model: 4000, reward:-2.5, precision@5 : 0.34148936170212785, ndcg@5 : 0.3619360504247451\n",
    "Model: 4500, reward:7.5, precision@5 : 0.29361702127659584, ndcg@5 : 0.30740030713082767\n",
    "Model: 5000, reward:6.5, precision@5 : 0.30000000000000004, ndcg@5 : 0.3186447822137763\n",
    "Model: 5500, reward:-18.5, precision@5 : 0.296808510638298, ndcg@5 : 0.31707982509204735\n",
    "Model: 6000, reward:0.0, precision@5 : 0.2510638297872341, ndcg@5 : 0.2611706296655829\n",
    "Model: 6500, reward:9.0, precision@5 : 0.2925531914893617, ndcg@5 : 0.3006211489004001\n",
    "Model: 7000, reward:-5.0, precision@5 : 0.2840425531914894, ndcg@5 : 0.3006564914005707\n",
    "Model: 7500, reward:4.5, precision@5 : 0.29361702127659595, ndcg@5 : 0.3026293633672475\n",
    "Model: 8000, reward:-4.5, precision@5 : 0.2680851063829788, ndcg@5 : 0.28273040784353415\n",
    "Model: 8500, reward:4.5, precision@5 : 0.30106382978723406, ndcg@5 : 0.31831107781526374\n",
    "Model: 9000, reward:-6.5, precision@5 : 0.2925531914893617, ndcg@5 : 0.29911295108523417\n",
    "Model: 9500, reward:-1.0, precision@5 : 0.28829787234042564, ndcg@5 : 0.29818113262552903\n",
    "Model: 10000, reward:-12.5, precision@5 : 0.2734042553191489, ndcg@5 : 0.2850720437354392\n",
    "Model: 10500, reward:9.5, precision@5 : 0.273404255319149, ndcg@5 : 0.2812973140889408\n",
    "Model: 11000, reward:-14.0, precision@5 : 0.2361702127659575, ndcg@5 : 0.24578928045705703\n",
    "Model: 11500, reward:-33.0, precision@5 : 0.224468085106383, ndcg@5 : 0.23461962889718316\n",
    "Model: 12000, reward:-7.5, precision@5 : 0.25744680851063817, ndcg@5 : 0.26718251297407164\n",
    "Model: 12500, reward:0.5, precision@5 : 0.2691489361702127, ndcg@5 : 0.28120949828402353\n",
    "Model: 13000, reward:-16.0, precision@5 : 0.26276595744680853, ndcg@5 : 0.2745160182409713\n",
    "Model: 13500, reward:8.5, precision@5 : 0.27978723404255323, ndcg@5 : 0.28869069560363303\n",
    "Model: 14000, reward:8.5, precision@5 : 0.274468085106383, ndcg@5 : 0.28911743034890114\n",
    "Model: 14500, reward:1.5, precision@5 : 0.29680851063829783, ndcg@5 : 0.31391206204787186\n",
    "Model: 15000, reward:5.0, precision@5 : 0.2936170212765958, ndcg@5 : 0.3083900976285509\n",
    "Model: 15500, reward:-8.0, precision@5 : 0.28510638297872337, ndcg@5 : 0.29897853428782134\n",
    "Model: 16000, reward:-14.0, precision@5 : 0.2797872340425532, ndcg@5 : 0.29332363291821717\n",
    "Model: 16500, reward:2.0, precision@5 : 0.2893617021276596, ndcg@5 : 0.3002436786951457\n",
    "Model: 17000, reward:10.5, precision@5 : 0.302127659574468, ndcg@5 : 0.32412847590569144\n",
    "Model: 17500, reward:20.5, precision@5 : 0.2957446808510639, ndcg@5 : 0.30534506487288277\n",
    "Model: 18000, reward:-3.0, precision@5 : 0.27340425531914897, ndcg@5 : 0.2817953286174521\n",
    "Model: 18500, reward:-2.0, precision@5 : 0.28723404255319157, ndcg@5 : 0.3031338027330956\n",
    "Model: 19000, reward:2.5, precision@5 : 0.2734042553191491, ndcg@5 : 0.2897148988435264\n",
    "Model: 19500, reward:-3.0, precision@5 : 0.2744680851063831, ndcg@5 : 0.28867486935401565\n",
    "Model: 20000, reward:1.5, precision@5 : 0.27340425531914897, ndcg@5 : 0.2902404261305604\n",
    "\n",
    "Model: 500, reward:-5.5, precision@10 : 0.2760638297872341, ndcg@10 : 0.29326504653381186\n",
    "Model: 1000, reward:-19.0, precision@10 : 0.22712765957446818, ndcg@10 : 0.23022659302777257\n",
    "Model: 1500, reward:-5.0, precision@10 : 0.2696808510638299, ndcg@10 : 0.3016028542172132\n",
    "Model: 2000, reward:-36.5, precision@10 : 0.2452127659574468, ndcg@10 : 0.27035206542800955\n",
    "Model: 2500, reward:-14.0, precision@10 : 0.2734042553191489, ndcg@10 : 0.2911219666491055\n",
    "Model: 3000, reward:-24.0, precision@10 : 0.25957446808510654, ndcg@10 : 0.2771031655612475\n",
    "Model: 3500, reward:-17.5, precision@10 : 0.2734042553191488, ndcg@10 : 0.2979938315427688\n",
    "Model: 4000, reward:-9.0, precision@10 : 0.27819148936170224, ndcg@10 : 0.31111124164980875\n",
    "Model: 4500, reward:-28.5, precision@10 : 0.24468085106382995, ndcg@10 : 0.26855551083266266\n",
    "Model: 5000, reward:-3.5, precision@10 : 0.2510638297872342, ndcg@10 : 0.27713502315410193\n",
    "Model: 5500, reward:-21.5, precision@10 : 0.24680851063829812, ndcg@10 : 0.27588437588571063\n",
    "Model: 6000, reward:-8.0, precision@10 : 0.22606382978723424, ndcg@10 : 0.2403676130660631\n",
    "Model: 6500, reward:-23.0, precision@10 : 0.23882978723404275, ndcg@10 : 0.26004216760773796\n",
    "Model: 7000, reward:-9.0, precision@10 : 0.2542553191489364, ndcg@10 : 0.27438274183993844\n",
    "Model: 7500, reward:-21.5, precision@10 : 0.25797872340425554, ndcg@10 : 0.2750797285446745\n",
    "Model: 8000, reward:-25.0, precision@10 : 0.2414893617021277, ndcg@10 : 0.25867781135517454\n",
    "Model: 8500, reward:-5.5, precision@10 : 0.2617021276595746, ndcg@10 : 0.2842823020591027\n",
    "Model: 9000, reward:-8.0, precision@10 : 0.2643617021276597, ndcg@10 : 0.2783946405010313\n",
    "Model: 9500, reward:-3.5, precision@10 : 0.25851063829787263, ndcg@10 : 0.2739548374414951\n",
    "Model: 10000, reward:-17.5, precision@10 : 0.2515957446808512, ndcg@10 : 0.26529240440154017\n",
    "Model: 10500, reward:-20.5, precision@10 : 0.24042553191489377, ndcg@10 : 0.2554461770216054\n",
    "Model: 11000, reward:-35.5, precision@10 : 0.20585106382978743, ndcg@10 : 0.22091401310839076\n",
    "Model: 11500, reward:-29.0, precision@10 : 0.1930851063829788, ndcg@10 : 0.20812876320349352\n",
    "Model: 12000, reward:-14.5, precision@10 : 0.23351063829787236, ndcg@10 : 0.24659222018817567\n",
    "Model: 12500, reward:-5.0, precision@10 : 0.22978723404255327, ndcg@10 : 0.24885235825676022\n",
    "Model: 13000, reward:-15.5, precision@10 : 0.2265957446808511, ndcg@10 : 0.2444619551908684\n",
    "Model: 13500, reward:-24.0, precision@10 : 0.24627659574468083, ndcg@10 : 0.26168471402810706\n",
    "Model: 14000, reward:-11.5, precision@10 : 0.23563829787234047, ndcg@10 : 0.2572233955927678\n",
    "Model: 14500, reward:-13.0, precision@10 : 0.2531914893617022, ndcg@10 : 0.2778343666065469\n",
    "Model: 15000, reward:-22.5, precision@10 : 0.2595744680851066, ndcg@10 : 0.2799881820598426\n",
    "Model: 15500, reward:-16.0, precision@10 : 0.247872340425532, ndcg@10 : 0.26800101196170695\n",
    "Model: 16000, reward:-18.0, precision@10 : 0.24734042553191504, ndcg@10 : 0.2647248864473573\n",
    "Model: 16500, reward:-23.0, precision@10 : 0.2505319148936171, ndcg@10 : 0.2687969445182846\n",
    "Model: 17000, reward:-4.5, precision@10 : 0.273936170212766, ndcg@10 : 0.29577282393327115\n",
    "Model: 17500, reward:-23.0, precision@10 : 0.26382978723404266, ndcg@10 : 0.2794620753865872\n",
    "Model: 18000, reward:-13.5, precision@10 : 0.2505319148936172, ndcg@10 : 0.2629603602758558\n",
    "Model: 18500, reward:-15.0, precision@10 : 0.25691489361702147, ndcg@10 : 0.27711449832710905\n",
    "Model: 19000, reward:-4.5, precision@10 : 0.24893617021276612, ndcg@10 : 0.2679346946931493\n",
    "Model: 19500, reward:-15.0, precision@10 : 0.24361702127659596, ndcg@10 : 0.26107498054707207\n",
    "Model: 20000, reward:-15.5, precision@10 : 0.25000000000000006, ndcg@10 : 0.2672941782202507"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0TATD3: 500000\n",
    "Model: 500, reward:17.0, precision@5 : 0.3319148936170213, ndcg@5 : 0.3562378076110438\n",
    "Model: 1000, reward:22.5, precision@5 : 0.3659574468085108, ndcg@5 : 0.39013395180754\n",
    "Model: 1500, reward:35.0, precision@5 : 0.35000000000000014, ndcg@5 : 0.37433169425424523\n",
    "Model: 2000, reward:11.5, precision@5 : 0.34574468085106397, ndcg@5 : 0.3659365068477183\n",
    "Model: 2500, reward:12.5, precision@5 : 0.3382978723404256, ndcg@5 : 0.3479495218074498\n",
    "Model: 3000, reward:2.5, precision@5 : 0.3265957446808511, ndcg@5 : 0.34423676722733104\n",
    "Model: 3500, reward:-16.0, precision@5 : 0.27872340425531916, ndcg@5 : 0.2960920023374118\n",
    "Model: 4000, reward:7.0, precision@5 : 0.28617021276595744, ndcg@5 : 0.2908700222707307\n",
    "Model: 4500, reward:12.5, precision@5 : 0.27978723404255323, ndcg@5 : 0.29317850528165135\n",
    "Model: 5000, reward:2.5, precision@5 : 0.30212765957446813, ndcg@5 : 0.3077239474747328\n",
    "Model: 5500, reward:4.0, precision@5 : 0.29680851063829794, ndcg@5 : 0.30145165631394694\n",
    "Model: 6000, reward:-7.5, precision@5 : 0.2574468085106382, ndcg@5 : 0.27037783590649983\n",
    "Model: 6500, reward:26.0, precision@5 : 0.27234042553191484, ndcg@5 : 0.2762687952228601\n",
    "Model: 7000, reward:2.0, precision@5 : 0.26808510638297867, ndcg@5 : 0.27810496894943476\n",
    "Model: 7500, reward:5.0, precision@5 : 0.26595744680851063, ndcg@5 : 0.2662043594195666\n",
    "Model: 8000, reward:-9.5, precision@5 : 0.2574468085106382, ndcg@5 : 0.26421240043689553\n",
    "Model: 8500, reward:9.0, precision@5 : 0.28191489361702143, ndcg@5 : 0.2866537568647862\n",
    "Model: 9000, reward:13.0, precision@5 : 0.2861702127659576, ndcg@5 : 0.29061147149847794\n",
    "Model: 9500, reward:3.5, precision@5 : 0.2606382978723405, ndcg@5 : 0.2631104442287137\n",
    "Model: 10000, reward:5.5, precision@5 : 0.2787234042553193, ndcg@5 : 0.28441688495827205\n",
    "Model: 10500, reward:-9.0, precision@5 : 0.2744680851063831, ndcg@5 : 0.285276117861797\n",
    "Model: 11000, reward:5.0, precision@5 : 0.2829787234042555, ndcg@5 : 0.28503246479913946\n",
    "Model: 11500, reward:-2.0, precision@5 : 0.2627659574468087, ndcg@5 : 0.25943372362708456\n",
    "Model: 12000, reward:-8.5, precision@5 : 0.2553191489361702, ndcg@5 : 0.25682059302879306\n",
    "Model: 12500, reward:-8.0, precision@5 : 0.2457446808510638, ndcg@5 : 0.2497362842515958\n",
    "Model: 13000, reward:-11.0, precision@5 : 0.24255319148936164, ndcg@5 : 0.24524623904263979\n",
    "Model: 13500, reward:-12.5, precision@5 : 0.24680851063829787, ndcg@5 : 0.25453702587032323\n",
    "Model: 14000, reward:-4.5, precision@5 : 0.25319148936170227, ndcg@5 : 0.2639910480268793\n",
    "Model: 14500, reward:-8.5, precision@5 : 0.24361702127659568, ndcg@5 : 0.2543529672999819\n",
    "Model: 15000, reward:-7.0, precision@5 : 0.2553191489361703, ndcg@5 : 0.2590425660077334\n",
    "Model: 15500, reward:0.5, precision@5 : 0.2531914893617022, ndcg@5 : 0.2549656636073873\n",
    "Model: 16000, reward:-3.0, precision@5 : 0.22765957446808516, ndcg@5 : 0.2281088013021825\n",
    "Model: 16500, reward:-17.5, precision@5 : 0.23085106382978723, ndcg@5 : 0.2317382607049465\n",
    "Model: 17000, reward:-17.5, precision@5 : 0.22553191489361693, ndcg@5 : 0.2250767644822922\n",
    "Model: 17500, reward:-30.5, precision@5 : 0.23829787234042554, ndcg@5 : 0.2440779358375769\n",
    "Model: 18000, reward:-6.5, precision@5 : 0.2563829787234042, ndcg@5 : 0.26449651141018815\n",
    "Model: 18500, reward:-19.0, precision@5 : 0.2521276595744681, ndcg@5 : 0.25882452271180256\n",
    "Model: 19000, reward:11.5, precision@5 : 0.2680851063829787, ndcg@5 : 0.26988303257867874\n",
    "Model: 19500, reward:6.0, precision@5 : 0.27234042553191495, ndcg@5 : 0.2742840021215319\n",
    "Model: 20000, reward:13.0, precision@5 : 0.2765957446808511, ndcg@5 : 0.27466887405185403\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0TATD3: 500000\n",
    "Model: 500, reward:-15.0, precision@10 : 0.29255319148936176, ndcg@10 : 0.320280577302055\n",
    "Model: 1000, reward:-4.5, precision@10 : 0.3186170212765957, ndcg@10 : 0.34770356475438274\n",
    "Model: 1500, reward:-14.5, precision@10 : 0.3010638297872341, ndcg@10 : 0.3314692862921681\n",
    "Model: 2000, reward:10.5, precision@10 : 0.3085106382978724, ndcg@10 : 0.3328368905594811\n",
    "Model: 2500, reward:-3.0, precision@10 : 0.29468085106383, ndcg@10 : 0.3141036722051297\n",
    "Model: 3000, reward:-11.0, precision@10 : 0.28617021276595755, ndcg@10 : 0.3097721982733523\n",
    "Model: 3500, reward:-8.5, precision@10 : 0.24946808510638308, ndcg@10 : 0.268919364362197\n",
    "Model: 4000, reward:-11.0, precision@10 : 0.25531914893617047, ndcg@10 : 0.2676340920807079\n",
    "Model: 4500, reward:4.0, precision@10 : 0.2622340425531917, ndcg@10 : 0.27544665730783313\n",
    "Model: 5000, reward:-8.5, precision@10 : 0.2654255319148937, ndcg@10 : 0.2796099786599057\n",
    "Model: 5500, reward:-19.0, precision@10 : 0.26329787234042573, ndcg@10 : 0.27713856735241743\n",
    "Model: 6000, reward:13.5, precision@10 : 0.24361702127659599, ndcg@10 : 0.25491216916102705\n",
    "Model: 6500, reward:-6.5, precision@10 : 0.25691489361702147, ndcg@10 : 0.2635864704491421\n",
    "Model: 7000, reward:-14.0, precision@10 : 0.25691489361702136, ndcg@10 : 0.2671186730233658\n",
    "Model: 7500, reward:-7.5, precision@10 : 0.24893617021276607, ndcg@10 : 0.2541460600890521\n",
    "Model: 8000, reward:-19.5, precision@10 : 0.2521276595744682, ndcg@10 : 0.25837312735039264\n",
    "Model: 8500, reward:-29.5, precision@10 : 0.25053191489361704, ndcg@10 : 0.2626648961743266\n",
    "Model: 9000, reward:-19.5, precision@10 : 0.2611702127659575, ndcg@10 : 0.2721410972333862\n",
    "Model: 9500, reward:-5.0, precision@10 : 0.23829787234042554, ndcg@10 : 0.24678387052376344\n",
    "Model: 10000, reward:-14.5, precision@10 : 0.2606382978723405, ndcg@10 : 0.2699746777625194\n",
    "Model: 10500, reward:-4.5, precision@10 : 0.25744680851063845, ndcg@10 : 0.26979647327165396\n",
    "Model: 11000, reward:-16.0, precision@10 : 0.2505319148936171, ndcg@10 : 0.26254162702781464\n",
    "Model: 11500, reward:-14.5, precision@10 : 0.24468085106382995, ndcg@10 : 0.24850641353046515\n",
    "Model: 12000, reward:15.0, precision@10 : 0.24042553191489383, ndcg@10 : 0.24583413213385805\n",
    "Model: 12500, reward:-29.0, precision@10 : 0.22978723404255338, ndcg@10 : 0.2379271460771815\n",
    "Model: 13000, reward:-15.0, precision@10 : 0.22446808510638308, ndcg@10 : 0.23182561686761582\n",
    "Model: 13500, reward:-21.0, precision@10 : 0.22872340425531934, ndcg@10 : 0.23984320349837432\n",
    "Model: 14000, reward:-38.0, precision@10 : 0.2287234042553193, ndcg@10 : 0.2436315600764545\n",
    "Model: 14500, reward:-16.5, precision@10 : 0.22819148936170222, ndcg@10 : 0.23988216262044637\n",
    "Model: 15000, reward:-18.5, precision@10 : 0.22446808510638308, ndcg@10 : 0.23703792339140767\n",
    "Model: 15500, reward:-14.0, precision@10 : 0.23670212765957455, ndcg@10 : 0.24301169933946468\n",
    "Model: 16000, reward:-9.5, precision@10 : 0.21382978723404272, ndcg@10 : 0.21860086978225543\n",
    "Model: 16500, reward:-24.0, precision@10 : 0.2148936170212767, ndcg@10 : 0.22030997039922923\n",
    "Model: 17000, reward:-16.0, precision@10 : 0.21755319148936192, ndcg@10 : 0.21972070409053976\n",
    "Model: 17500, reward:-23.5, precision@10 : 0.21489361702127677, ndcg@10 : 0.2258489833361713\n",
    "Model: 18000, reward:-14.5, precision@10 : 0.2281914893617024, ndcg@10 : 0.24236945314328076\n",
    "Model: 18500, reward:-23.5, precision@10 : 0.24787234042553208, ndcg@10 : 0.25428507760351304\n",
    "Model: 19000, reward:-17.0, precision@10 : 0.24680851063829798, ndcg@10 : 0.2547422141430581\n",
    "Model: 19500, reward:-16.0, precision@10 : 0.2515957446808513, ndcg@10 : 0.26001500677201067\n",
    "Model: 20000, reward:15.0, precision@10 : 0.26382978723404277, ndcg@10 : 0.26635100925956257"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "RL_ActorCritic_DDPG_Movie_Recommendation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
