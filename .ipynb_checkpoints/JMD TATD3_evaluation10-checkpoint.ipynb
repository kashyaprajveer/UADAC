{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r1NmejTIFPtf"
   },
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from envs1 import OfflineEnv\n",
    "from recommender import DRRAgent\n",
    "\n",
    "STATE_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df=pd.read_csv('./movies.dat')\n",
    "movies_list=movies_df.values.tolist()\n",
    "movies_id_to_movies = {movie[0]: movie[1:] for movie in movies_list}\n",
    "movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)\n",
    "ratings_df=pd.read_csv('./ratings.dat')\n",
    "ratings_df = ratings_df.applymap(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_dict = np.load('./user_dict.npy', allow_pickle=True)\n",
    "users_history_lens = np.load('./users_histroy_len.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유저별로 본 영화들 순서대로 정리\n",
    "users_dict = {user : [] for user in set(ratings_df[\"UserID\"])}\n",
    "users_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>255</td>\n",
       "      <td>4</td>\n",
       "      <td>874724710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259</td>\n",
       "      <td>286</td>\n",
       "      <td>4</td>\n",
       "      <td>874724727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259</td>\n",
       "      <td>298</td>\n",
       "      <td>4</td>\n",
       "      <td>874724754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>259</td>\n",
       "      <td>185</td>\n",
       "      <td>4</td>\n",
       "      <td>874724781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259</td>\n",
       "      <td>173</td>\n",
       "      <td>4</td>\n",
       "      <td>874724843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0     259      255       4  874724710\n",
       "1     259      286       4  874724727\n",
       "2     259      298       4  874724754\n",
       "3     259      185       4  874724781\n",
       "4     259      173       4  874724843"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by time\n",
    "ratings_df = ratings_df.sort_values(by='Timestamp', ascending=True)\n",
    "ratings_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put (movie, rating) pairs in user dictionary\n",
    "# Only movies with a rating of 4 or higher are counted for each user's movie history length.\n",
    "ratings_df_gen = ratings_df.iterrows()\n",
    "users_dict_for_history_len = {user : [] for user in set(ratings_df[\"UserID\"])}\n",
    "for data in ratings_df_gen:\n",
    "    users_dict[data[1]['UserID']].append((data[1]['MovieID'], data[1]['Rating']))\n",
    "    if data[1]['Rating'] >= 1:\n",
    "        users_dict_for_history_len[data[1]['UserID']].append((data[1]['MovieID'], data[1]['Rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Movie history length for each user\n",
    "users_history_lens = [len(users_dict_for_history_len[u]) for u in set(ratings_df[\"UserID\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users_history_lens)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.save(\"./data/user_dict.npy\", users_dict)\n",
    "np.save(\"./data/users_histroy_len.npy\", users_history_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_num = max(ratings_df[\"UserID\"])+1\n",
    "items_num = max(ratings_df[\"MovieID\"])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944 1683\n"
     ]
    }
   ],
   "source": [
    "print(users_num, items_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755 1683\n"
     ]
    }
   ],
   "source": [
    "train_users_num = int(users_num * 0.8)\n",
    "train_items_num = items_num\n",
    "print(train_users_num, train_items_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755 755\n"
     ]
    }
   ],
   "source": [
    "train_users_dict = {k:users_dict[k] for k in range(1, train_users_num+1)}\n",
    "train_users_history_lens = users_history_lens[:train_users_num]\n",
    "print(len(train_users_dict),len(train_users_history_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 1683\n"
     ]
    }
   ],
   "source": [
    "eval_users_num = int(users_num * 0.2)\n",
    "eval_items_num = items_num\n",
    "print(eval_users_num, eval_items_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 188\n"
     ]
    }
   ],
   "source": [
    "eval_users_dict = {k:users_dict[k] for k in range(users_num-eval_users_num, users_num)}\n",
    "eval_users_history_lens = users_history_lens[-eval_users_num:]\n",
    "print(len(eval_users_dict),len(eval_users_history_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(recommender, env, check_movies = False, top_k=False, length = False):\n",
    "\n",
    "    # episodic reward \n",
    "    mean_precision = 0\n",
    "    mean_ndcg = 0\n",
    "\n",
    "  # episodic reward\n",
    "    episode_reward = 0\n",
    "    steps = 0\n",
    "    q_loss1 = 0\n",
    "    q_loss2 = 0\n",
    "    countl = 0\n",
    "    correct_list = []\n",
    "    \n",
    "    # Environment \n",
    "    user_id, items_ids, done = env.reset()\n",
    "\n",
    "    while not done:\n",
    "#         print(\"user_id :\",user_id)\n",
    "        # Observe current state & Find action\n",
    "        ## Embedding\n",
    "        user_eb = recommender.embedding_network.get_layer('user_embedding')(np.array(user_id))\n",
    "        items_eb = recommender.embedding_network.get_layer('movie_embedding')(np.array(items_ids))\n",
    "        ## SRM state \n",
    "        state = recommender.srm_ave([np.expand_dims(user_eb, axis=0), np.expand_dims(items_eb, axis=0)])\n",
    "        ## Action(ranking score) \n",
    "        action1 = recommender.actor.network(state)\n",
    "        action2 = recommender.actor2.network(state)\n",
    "        \n",
    "        q11 = recommender.critic.network([action1, state])\n",
    "        q12 = recommender.critic2.network([action2, state])\n",
    "\n",
    "        action = action1 if q11 >= q12 else action2\n",
    "        \n",
    "        \n",
    "        ## Item \n",
    "        recommended_item = recommender.recommend_item(action, env.recommended_items, top_k=top_k)\n",
    "\n",
    "        next_items_ids, reward, done, _ = env.step(recommended_item, top_k=top_k)\n",
    "        \n",
    "#         print(\"done :\",done)\n",
    "\n",
    "        if countl < length:\n",
    "            countl += 1\n",
    "#             print(\"countl :\",countl)\n",
    "            correct_list.append(reward)\n",
    "            if done == True or countl == length:\n",
    "                dcg, idcg = calculate_ndcg(correct_list, [1 for _ in range(len(correct_list))])\n",
    "#                 print(\"dcg :\", dcg, \"idcg :\", idcg)\n",
    "                mean_ndcg += dcg/idcg\n",
    "#                 print(\"mean_ndcg :\",mean_ndcg)\n",
    "\n",
    "                #precision\n",
    "                correct_list1 = [1 if r > 0 else 0 for r in correct_list]\n",
    "                correct_num = length-correct_list1.count(0)\n",
    "                mean_precision += correct_num/length\n",
    "                   \n",
    "        items_ids = next_items_ids\n",
    "        episode_reward += reward\n",
    "        steps += 1\n",
    "        \n",
    "    return mean_precision, mean_ndcg, reward\n",
    "\n",
    "def calculate_ndcg(rel, irel):\n",
    "    dcg = 0\n",
    "    idcg = 0\n",
    "    rel = [1 if r>0 else 0 for r in rel]\n",
    "    for i, (r, ir) in enumerate(zip(rel, irel)):\n",
    "        dcg += (r)/np.log2(i+2)\n",
    "        idcg += (ir)/np.log2(i+2)\n",
    "    return dcg, idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 500, reward:-39.0, precision@5 : 0.1851063829787233, ndcg@5 : 0.1956842090837017\n",
      "Model: 1000, reward:-20.5, precision@5 : 0.21489361702127663, ndcg@5 : 0.22436299053649636\n",
      "Model: 1500, reward:-15.5, precision@5 : 0.2553191489361703, ndcg@5 : 0.27831006952921034\n",
      "Model: 2000, reward:-12.0, precision@5 : 0.25851063829787246, ndcg@5 : 0.27417933604953676\n",
      "Model: 2500, reward:6.5, precision@5 : 0.2957446808510639, ndcg@5 : 0.31150673905266857\n",
      "Model: 3000, reward:-14.5, precision@5 : 0.2819148936170215, ndcg@5 : 0.2945260671099737\n",
      "Model: 3500, reward:1.0, precision@5 : 0.272340425531915, ndcg@5 : 0.2823853482572797\n",
      "Model: 4000, reward:-12.0, precision@5 : 0.28829787234042553, ndcg@5 : 0.30595426944210047\n",
      "Model: 4500, reward:-9.0, precision@5 : 0.23829787234042568, ndcg@5 : 0.2462435267428693\n",
      "Model: 5000, reward:-27.0, precision@5 : 0.2276595744680851, ndcg@5 : 0.2394783401179719\n",
      "Model: 5500, reward:-19.5, precision@5 : 0.25000000000000006, ndcg@5 : 0.2654594830636648\n",
      "Model: 6000, reward:-6.5, precision@5 : 0.22127659574468087, ndcg@5 : 0.22214096799186894\n",
      "Model: 6500, reward:7.0, precision@5 : 0.26170212765957435, ndcg@5 : 0.2694446608901922\n",
      "Model: 7000, reward:-8.5, precision@5 : 0.27446808510638304, ndcg@5 : 0.28755256748663244\n",
      "Model: 7500, reward:-9.5, precision@5 : 0.28191489361702143, ndcg@5 : 0.29140659050010254\n",
      "Model: 8000, reward:-19.0, precision@5 : 0.2659574468085106, ndcg@5 : 0.27911715557723793\n",
      "Model: 8500, reward:-3.5, precision@5 : 0.2851063829787235, ndcg@5 : 0.3018536639207589\n",
      "Model: 9000, reward:-4.5, precision@5 : 0.2691489361702128, ndcg@5 : 0.2809489949542878\n",
      "Model: 9500, reward:-7.0, precision@5 : 0.26595744680851063, ndcg@5 : 0.2830884137998793\n",
      "Model: 10000, reward:-45.0, precision@5 : 0.2553191489361703, ndcg@5 : 0.2679922008000852\n",
      "Model: 10500, reward:-11.5, precision@5 : 0.2680851063829788, ndcg@5 : 0.27144216573586505\n",
      "Model: 11000, reward:-28.5, precision@5 : 0.223404255319149, ndcg@5 : 0.23070046796435187\n",
      "Model: 11500, reward:-26.5, precision@5 : 0.20212765957446802, ndcg@5 : 0.20848362679945912\n",
      "Model: 12000, reward:-24.5, precision@5 : 0.23723404255319147, ndcg@5 : 0.2520746134653722\n",
      "Model: 12500, reward:-7.5, precision@5 : 0.24468085106382995, ndcg@5 : 0.2548872504327291\n",
      "Model: 13000, reward:-9.5, precision@5 : 0.2372340425531916, ndcg@5 : 0.24238112633457928\n",
      "Model: 13500, reward:-14.0, precision@5 : 0.24680851063829798, ndcg@5 : 0.25550092484584364\n",
      "Model: 14000, reward:-8.5, precision@5 : 0.24680851063829795, ndcg@5 : 0.26005280007805365\n",
      "Model: 14500, reward:12.0, precision@5 : 0.2765957446808512, ndcg@5 : 0.2809156533593088\n",
      "Model: 15000, reward:-17.5, precision@5 : 0.2510638297872342, ndcg@5 : 0.2619155568051504\n",
      "Model: 15500, reward:-5.0, precision@5 : 0.23829787234042563, ndcg@5 : 0.2463643999513324\n",
      "Model: 16000, reward:-19.5, precision@5 : 0.25319148936170216, ndcg@5 : 0.2620587777959848\n",
      "Model: 16500, reward:-13.0, precision@5 : 0.26063829787234033, ndcg@5 : 0.2751808130561652\n",
      "Model: 17000, reward:-19.5, precision@5 : 0.27340425531914897, ndcg@5 : 0.29544424772126904\n",
      "Model: 17500, reward:1.5, precision@5 : 0.2734042553191489, ndcg@5 : 0.28575494867889684\n",
      "Model: 18000, reward:-11.5, precision@5 : 0.25106382978723396, ndcg@5 : 0.25568562898275227\n",
      "Model: 18500, reward:16.0, precision@5 : 0.2691489361702129, ndcg@5 : 0.28046266571670336\n",
      "Model: 19000, reward:-7.5, precision@5 : 0.2712765957446809, ndcg@5 : 0.2834101487160318\n",
      "Model: 19500, reward:-13.5, precision@5 : 0.2542553191489361, ndcg@5 : 0.2633816112678726\n",
      "Model: 20000, reward:-1.5, precision@5 : 0.275531914893617, ndcg@5 : 0.28721267287652924\n"
     ]
    }
   ],
   "source": [
    "sum_precision = 0\n",
    "sum_ndcg = 0\n",
    "sum_reward = 0\n",
    "for i in range(1,41):\n",
    "    sum_precision = 0\n",
    "    sum_ndcg = 0\n",
    "    sum_reward = 0\n",
    "    length_k = 5\n",
    "    for user_id in eval_users_dict.keys():\n",
    "        env = OfflineEnv(eval_users_dict, users_history_lens, movies_id_to_movies, STATE_SIZE, fix_user_id=user_id)\n",
    "        recommender = DRRAgent(env, users_num, items_num, STATE_SIZE)\n",
    "        recommender.actor.build_networks()\n",
    "        recommender.actor2.build_networks()\n",
    "        recommender.critic.build_networks()\n",
    "        recommender.critic2.build_networks()\n",
    "        recommender.load_model(f\"./save_weights/actor_{i*500}_fixed.h5\", \n",
    "                               f\"./save_weights/actor2_{i*500}_fixed.h5\", \n",
    "                               f\"./save_weights/critic_{i*500}_fixed.h5\",\n",
    "                              f\"./save_weights/critic2_{i*500}_fixed.h5\")\n",
    "        precision, ndcg, reward = evaluate(recommender, env, top_k= False, length = length_k)\n",
    "        sum_precision += precision\n",
    "        sum_ndcg += ndcg\n",
    "        sum_reward += reward\n",
    "\n",
    "    print(f'Model: {i*500}, reward:{sum_reward}, precision@{length_k} : {sum_precision/len(eval_users_dict)}, ndcg@{length_k} : {sum_ndcg/len(eval_users_dict)}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model: 500, reward:-39.0, precision@5 : 0.1851063829787233, ndcg@5 : 0.1956842090837017\n",
    "Model: 1000, reward:-20.5, precision@5 : 0.21489361702127663, ndcg@5 : 0.22436299053649636\n",
    "Model: 1500, reward:-15.5, precision@5 : 0.2553191489361703, ndcg@5 : 0.27831006952921034\n",
    "Model: 2000, reward:-12.0, precision@5 : 0.25851063829787246, ndcg@5 : 0.27417933604953676\n",
    "Model: 2500, reward:6.5, precision@5 : 0.2957446808510639, ndcg@5 : 0.31150673905266857\n",
    "Model: 3000, reward:-14.5, precision@5 : 0.2819148936170215, ndcg@5 : 0.2945260671099737\n",
    "Model: 3500, reward:1.0, precision@5 : 0.272340425531915, ndcg@5 : 0.2823853482572797\n",
    "Model: 4000, reward:-12.0, precision@5 : 0.28829787234042553, ndcg@5 : 0.30595426944210047\n",
    "Model: 4500, reward:-9.0, precision@5 : 0.23829787234042568, ndcg@5 : 0.2462435267428693\n",
    "Model: 5000, reward:-27.0, precision@5 : 0.2276595744680851, ndcg@5 : 0.2394783401179719\n",
    "Model: 5500, reward:-19.5, precision@5 : 0.25000000000000006, ndcg@5 : 0.2654594830636648\n",
    "Model: 6000, reward:-6.5, precision@5 : 0.22127659574468087, ndcg@5 : 0.22214096799186894\n",
    "Model: 6500, reward:7.0, precision@5 : 0.26170212765957435, ndcg@5 : 0.2694446608901922\n",
    "Model: 7000, reward:-8.5, precision@5 : 0.27446808510638304, ndcg@5 : 0.28755256748663244\n",
    "Model: 7500, reward:-9.5, precision@5 : 0.28191489361702143, ndcg@5 : 0.29140659050010254\n",
    "Model: 8000, reward:-19.0, precision@5 : 0.2659574468085106, ndcg@5 : 0.27911715557723793\n",
    "Model: 8500, reward:-3.5, precision@5 : 0.2851063829787235, ndcg@5 : 0.3018536639207589\n",
    "Model: 9000, reward:-4.5, precision@5 : 0.2691489361702128, ndcg@5 : 0.2809489949542878\n",
    "Model: 9500, reward:-7.0, precision@5 : 0.26595744680851063, ndcg@5 : 0.2830884137998793\n",
    "Model: 10000, reward:-45.0, precision@5 : 0.2553191489361703, ndcg@5 : 0.2679922008000852\n",
    "Model: 10500, reward:-11.5, precision@5 : 0.2680851063829788, ndcg@5 : 0.27144216573586505\n",
    "Model: 11000, reward:-28.5, precision@5 : 0.223404255319149, ndcg@5 : 0.23070046796435187\n",
    "Model: 11500, reward:-26.5, precision@5 : 0.20212765957446802, ndcg@5 : 0.20848362679945912\n",
    "Model: 12000, reward:-24.5, precision@5 : 0.23723404255319147, ndcg@5 : 0.2520746134653722\n",
    "Model: 12500, reward:-7.5, precision@5 : 0.24468085106382995, ndcg@5 : 0.2548872504327291\n",
    "Model: 13000, reward:-9.5, precision@5 : 0.2372340425531916, ndcg@5 : 0.24238112633457928\n",
    "Model: 13500, reward:-14.0, precision@5 : 0.24680851063829798, ndcg@5 : 0.25550092484584364\n",
    "Model: 14000, reward:-8.5, precision@5 : 0.24680851063829795, ndcg@5 : 0.26005280007805365\n",
    "Model: 14500, reward:12.0, precision@5 : 0.2765957446808512, ndcg@5 : 0.2809156533593088\n",
    "Model: 15000, reward:-17.5, precision@5 : 0.2510638297872342, ndcg@5 : 0.2619155568051504\n",
    "Model: 15500, reward:-5.0, precision@5 : 0.23829787234042563, ndcg@5 : 0.2463643999513324\n",
    "Model: 16000, reward:-19.5, precision@5 : 0.25319148936170216, ndcg@5 : 0.2620587777959848\n",
    "Model: 16500, reward:-13.0, precision@5 : 0.26063829787234033, ndcg@5 : 0.2751808130561652\n",
    "Model: 17000, reward:-19.5, precision@5 : 0.27340425531914897, ndcg@5 : 0.29544424772126904\n",
    "Model: 17500, reward:1.5, precision@5 : 0.2734042553191489, ndcg@5 : 0.28575494867889684\n",
    "Model: 18000, reward:-11.5, precision@5 : 0.25106382978723396, ndcg@5 : 0.25568562898275227\n",
    "Model: 18500, reward:16.0, precision@5 : 0.2691489361702129, ndcg@5 : 0.28046266571670336\n",
    "Model: 19000, reward:-7.5, precision@5 : 0.2712765957446809, ndcg@5 : 0.2834101487160318\n",
    "Model: 19500, reward:-13.5, precision@5 : 0.2542553191489361, ndcg@5 : 0.2633816112678726\n",
    "Model: 20000, reward:-1.5, precision@5 : 0.275531914893617, ndcg@5 : 0.28721267287652924\n",
    "\n",
    "Model: 500, reward:-28.5, precision@10 : 0.16542553191489368, ndcg@10 : 0.17650257750898912\n",
    "Model: 1000, reward:-30.0, precision@10 : 0.20425531914893624, ndcg@10 : 0.21401900400456406\n",
    "Model: 1500, reward:-33.5, precision@10 : 0.21329787234042555, ndcg@10 : 0.2405772565726865\n",
    "Model: 2000, reward:-27.5, precision@10 : 0.2250000000000001, ndcg@10 : 0.2454970111383587\n",
    "Model: 2500, reward:-18.0, precision@10 : 0.26702127659574476, ndcg@10 : 0.2860955041229601\n",
    "Model: 3000, reward:-35.5, precision@10 : 0.23776595744680856, ndcg@10 : 0.2592060152349581\n",
    "Model: 3500, reward:-27.5, precision@10 : 0.23936170212765961, ndcg@10 : 0.2582159973033566\n",
    "Model: 4000, reward:-28.0, precision@10 : 0.25265957446808524, ndcg@10 : 0.27599265016172536\n",
    "Model: 4500, reward:-42.0, precision@10 : 0.20053191489361716, ndcg@10 : 0.21882162011774112\n",
    "Model: 5000, reward:-10.0, precision@10 : 0.20212765957446813, ndcg@10 : 0.21806449245156892\n",
    "Model: 5500, reward:-25.5, precision@10 : 0.22287234042553206, ndcg@10 : 0.240571373216956\n",
    "Model: 6000, reward:-24.0, precision@10 : 0.19042553191489373, ndcg@10 : 0.19862348893692675\n",
    "Model: 6500, reward:-39.0, precision@10 : 0.2292553191489362, ndcg@10 : 0.24461568767516859\n",
    "Model: 7000, reward:-23.0, precision@10 : 0.2446808510638299, ndcg@10 : 0.26510508878718364\n",
    "Model: 7500, reward:-20.0, precision@10 : 0.24414893617021283, ndcg@10 : 0.26224656036585003\n",
    "Model: 8000, reward:-35.0, precision@10 : 0.22287234042553206, ndcg@10 : 0.24466738374427613\n",
    "Model: 8500, reward:-37.5, precision@10 : 0.2409574468085108, ndcg@10 : 0.2665052498333249\n",
    "Model: 9000, reward:-12.5, precision@10 : 0.24095744680851078, ndcg@10 : 0.253939249661823\n",
    "Model: 9500, reward:-11.0, precision@10 : 0.24414893617021294, ndcg@10 : 0.26127844887145796\n",
    "Model: 10000, reward:-8.0, precision@10 : 0.23138297872340433, ndcg@10 : 0.24444238817162192\n",
    "Model: 10500, reward:-23.5, precision@10 : 0.22659574468085122, ndcg@10 : 0.2394027821336489\n",
    "Model: 11000, reward:-32.0, precision@10 : 0.18457446808510639, ndcg@10 : 0.20048062792438223\n",
    "Model: 11500, reward:-39.5, precision@10 : 0.17819148936170223, ndcg@10 : 0.1883336938812113\n",
    "Model: 12000, reward:-18.0, precision@10 : 0.21223404255319153, ndcg@10 : 0.22710100780103368\n",
    "Model: 12500, reward:-43.5, precision@10 : 0.2196808510638298, ndcg@10 : 0.23017047295111406\n",
    "Model: 13000, reward:-22.5, precision@10 : 0.22234042553191496, ndcg@10 : 0.2306629761587439\n",
    "Model: 13500, reward:-43.0, precision@10 : 0.21914893617021294, ndcg@10 : 0.23299918429908847\n",
    "Model: 14000, reward:-26.5, precision@10 : 0.2117021276595745, ndcg@10 : 0.23027712913808984\n",
    "Model: 14500, reward:-14.0, precision@10 : 0.24095744680851078, ndcg@10 : 0.25217517297426395\n",
    "Model: 15000, reward:-19.5, precision@10 : 0.23085106382978726, ndcg@10 : 0.24116761253919317\n",
    "Model: 15500, reward:-30.0, precision@10 : 0.2127659574468085, ndcg@10 : 0.22142890705478552\n",
    "Model: 16000, reward:-21.5, precision@10 : 0.2271276595744682, ndcg@10 : 0.24192274014521725\n",
    "Model: 16500, reward:-5.0, precision@10 : 0.23829787234042554, ndcg@10 : 0.2547270593268185\n",
    "Model: 17000, reward:-17.5, precision@10 : 0.24946808510638313, ndcg@10 : 0.2715582088261252\n",
    "Model: 17500, reward:-18.5, precision@10 : 0.24361702127659585, ndcg@10 : 0.2561343451359504\n",
    "Model: 18000, reward:-19.0, precision@10 : 0.22872340425531934, ndcg@10 : 0.23775721369834737\n",
    "Model: 18500, reward:-26.5, precision@10 : 0.23138297872340438, ndcg@10 : 0.2480745922003482\n",
    "Model: 19000, reward:-17.0, precision@10 : 0.23936170212765975, ndcg@10 : 0.2555353175431133\n",
    "Model: 19500, reward:-21.0, precision@10 : 0.22606382978723405, ndcg@10 : 0.24230438502988158\n",
    "Model: 20000, reward:7.5, precision@10 : 0.23882978723404275, ndcg@10 : 0.2523111969116741"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0TATD3: 500000\n",
    "Model: 500, reward:-27.5, precision@5 : 0.25, ndcg@5 : 0.2695046362693589\n",
    "Model: 1000, reward:7.5, precision@5 : 0.3351063829787234, ndcg@5 : 0.3600286464806144\n",
    "Model: 1500, reward:8.0, precision@5 : 0.3180851063829789, ndcg@5 : 0.34250102679055794\n",
    "Model: 2000, reward:12.5, precision@5 : 0.32872340425531926, ndcg@5 : 0.3426252078951282\n",
    "Model: 2500, reward:12.0, precision@5 : 0.3042553191489363, ndcg@5 : 0.3196449510115109\n",
    "Model: 3000, reward:3.0, precision@5 : 0.27234042553191484, ndcg@5 : 0.29002364147783644\n",
    "Model: 3500, reward:-14.0, precision@5 : 0.2148936170212767, ndcg@5 : 0.22339578244689054\n",
    "Model: 4000, reward:-5.5, precision@5 : 0.24680851063829776, ndcg@5 : 0.2526548979357989\n",
    "Model: 4500, reward:8.5, precision@5 : 0.2723404255319149, ndcg@5 : 0.27382780206025825\n",
    "Model: 5000, reward:-2.0, precision@5 : 0.27978723404255346, ndcg@5 : 0.28959504965252403\n",
    "Model: 5500, reward:-19.0, precision@5 : 0.26276595744680864, ndcg@5 : 0.27570671879409253\n",
    "Model: 6000, reward:-18.0, precision@5 : 0.20957446808510632, ndcg@5 : 0.21342339888464334\n",
    "Model: 6500, reward:-21.0, precision@5 : 0.22021276595744668, ndcg@5 : 0.22429366331073608\n",
    "Model: 7000, reward:-14.0, precision@5 : 0.23829787234042554, ndcg@5 : 0.24503792848015277\n",
    "Model: 7500, reward:-4.0, precision@5 : 0.23617021276595732, ndcg@5 : 0.23657331715244836\n",
    "Model: 8000, reward:-6.0, precision@5 : 0.24680851063829798, ndcg@5 : 0.24886405906622847\n",
    "Model: 8500, reward:3.5, precision@5 : 0.2648936170212766, ndcg@5 : 0.2582121540716251\n",
    "Model: 9000, reward:7.0, precision@5 : 0.26170212765957435, ndcg@5 : 0.2612487115190778\n",
    "Model: 9500, reward:-18.0, precision@5 : 0.2372340425531914, ndcg@5 : 0.24378954008044654\n",
    "Model: 10000, reward:-10.0, precision@5 : 0.2521276595744681, ndcg@5 : 0.2570762143558322\n",
    "Model: 10500, reward:-22.0, precision@5 : 0.24148936170212756, ndcg@5 : 0.24849729848214855\n",
    "Model: 11000, reward:-16.0, precision@5 : 0.25106382978723396, ndcg@5 : 0.2630793418186077\n",
    "Model: 11500, reward:-8.0, precision@5 : 0.25212765957446814, ndcg@5 : 0.24932966175776133\n",
    "Model: 12000, reward:-20.5, precision@5 : 0.2351063829787235, ndcg@5 : 0.2381913496696965\n",
    "Model: 12500, reward:-16.5, precision@5 : 0.2489361702127659, ndcg@5 : 0.25586083501196333\n",
    "Model: 13000, reward:-12.0, precision@5 : 0.24148936170212762, ndcg@5 : 0.24703631351813912\n",
    "Model: 13500, reward:-13.5, precision@5 : 0.2340425531914893, ndcg@5 : 0.24195243903182823\n",
    "Model: 14000, reward:-16.0, precision@5 : 0.24680851063829795, ndcg@5 : 0.255218719300304\n",
    "Model: 14500, reward:-27.5, precision@5 : 0.23510638297872338, ndcg@5 : 0.24665698623284021\n",
    "Model: 15000, reward:-20.5, precision@5 : 0.22872340425531912, ndcg@5 : 0.2356211046858332\n",
    "Model: 15500, reward:-16.5, precision@5 : 0.23191489361702125, ndcg@5 : 0.23758745633773454\n",
    "Model: 16000, reward:-26.0, precision@5 : 0.20744680851063818, ndcg@5 : 0.21279282585674214\n",
    "Model: 16500, reward:-12.0, precision@5 : 0.21914893617021278, ndcg@5 : 0.22024720311412643\n",
    "Model: 17000, reward:-5.5, precision@5 : 0.22659574468085106, ndcg@5 : 0.22585600645063386\n",
    "Model: 17500, reward:-24.5, precision@5 : 0.2351063829787235, ndcg@5 : 0.24504630709295105\n",
    "Model: 18000, reward:-8.0, precision@5 : 0.25425531914893623, ndcg@5 : 0.260255614343226\n",
    "Model: 18500, reward:-13.0, precision@5 : 0.25106382978723407, ndcg@5 : 0.2613650194062054\n",
    "Model: 19000, reward:-17.5, precision@5 : 0.23510638297872336, ndcg@5 : 0.2459247212719305\n",
    "Model: 19500, reward:-12.0, precision@5 : 0.2659574468085107, ndcg@5 : 0.27020029765093423\n",
    "Model: 20000, reward:-12.0, precision@5 : 0.26170212765957446, ndcg@5 : 0.26285161170098464"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0TATD3: 500000\n",
    "Model: 500, reward:-34.0, precision@10 : 0.22340425531914904, ndcg@10 : 0.24358289454081888\n",
    "Model: 1000, reward:-22.0, precision@10 : 0.2792553191489364, ndcg@10 : 0.31362238172469864\n",
    "Model: 1500, reward:-14.5, precision@10 : 0.2765957446808512, ndcg@10 : 0.30546217149082955\n",
    "Model: 2000, reward:-14.0, precision@10 : 0.2797872340425533, ndcg@10 : 0.3042534891377031\n",
    "Model: 2500, reward:-17.0, precision@10 : 0.2808510638297875, ndcg@10 : 0.2984635640995332\n",
    "Model: 3000, reward:-26.0, precision@10 : 0.2542553191489363, ndcg@10 : 0.2721886239210859\n",
    "Model: 3500, reward:-30.5, precision@10 : 0.2095744680851064, ndcg@10 : 0.2151829428738867\n",
    "Model: 4000, reward:-20.5, precision@10 : 0.22500000000000006, ndcg@10 : 0.23602032862535227\n",
    "Model: 4500, reward:-10.0, precision@10 : 0.23776595744680856, ndcg@10 : 0.24741507162587267\n",
    "Model: 5000, reward:-14.0, precision@10 : 0.23882978723404266, ndcg@10 : 0.25945079701583157\n",
    "Model: 5500, reward:-28.5, precision@10 : 0.22765957446808513, ndcg@10 : 0.2452485739211157\n",
    "Model: 6000, reward:-28.5, precision@10 : 0.20000000000000012, ndcg@10 : 0.20762173814660906\n",
    "Model: 6500, reward:-31.0, precision@10 : 0.20585106382978743, ndcg@10 : 0.21024256460731636\n",
    "Model: 7000, reward:-28.0, precision@10 : 0.21489361702127674, ndcg@10 : 0.22589894122062737\n",
    "Model: 7500, reward:-31.0, precision@10 : 0.21702127659574477, ndcg@10 : 0.2236483987601234\n",
    "Model: 8000, reward:-24.5, precision@10 : 0.2260638297872343, ndcg@10 : 0.2352214755073018\n",
    "Model: 8500, reward:-22.0, precision@10 : 0.23404255319148948, ndcg@10 : 0.24015982197885555\n",
    "Model: 9000, reward:-24.0, precision@10 : 0.23404255319148948, ndcg@10 : 0.24139423618780653\n",
    "Model: 9500, reward:-25.0, precision@10 : 0.21914893617021286, ndcg@10 : 0.2284316976080464\n",
    "Model: 10000, reward:-21.5, precision@10 : 0.23723404255319164, ndcg@10 : 0.24597969112281465\n",
    "Model: 10500, reward:-18.5, precision@10 : 0.23617021276595757, ndcg@10 : 0.23813607810095522\n",
    "Model: 11000, reward:-39.5, precision@10 : 0.22606382978723427, ndcg@10 : 0.2423076150699813\n",
    "Model: 11500, reward:-12.0, precision@10 : 0.2340425531914896, ndcg@10 : 0.238911755518469\n",
    "Model: 12000, reward:-22.0, precision@10 : 0.22872340425531934, ndcg@10 : 0.23182911914065207\n",
    "Model: 12500, reward:-41.5, precision@10 : 0.22500000000000014, ndcg@10 : 0.2367516056195216\n",
    "Model: 13000, reward:-28.0, precision@10 : 0.21117021276595765, ndcg@10 : 0.22465184526188528\n",
    "Model: 13500, reward:-33.5, precision@10 : 0.2015957446808512, ndcg@10 : 0.21594791412140424\n",
    "Model: 14000, reward:-30.0, precision@10 : 0.21329787234042571, ndcg@10 : 0.22739277258768079\n",
    "Model: 14500, reward:-39.5, precision@10 : 0.20691489361702145, ndcg@10 : 0.22435283760366953\n",
    "Model: 15000, reward:-24.5, precision@10 : 0.2202127659574469, ndcg@10 : 0.23094796408554483\n",
    "Model: 15500, reward:-6.5, precision@10 : 0.22021276595744696, ndcg@10 : 0.22833586439232267\n",
    "Model: 16000, reward:-23.5, precision@10 : 0.19148936170212774, ndcg@10 : 0.20097078981116814\n",
    "Model: 16500, reward:-21.5, precision@10 : 0.2106382978723406, ndcg@10 : 0.21588270447802702\n",
    "Model: 17000, reward:-26.5, precision@10 : 0.20691489361702145, ndcg@10 : 0.2120905435094031\n",
    "Model: 17500, reward:-19.0, precision@10 : 0.21595744680851078, ndcg@10 : 0.22863226915593218\n",
    "Model: 18000, reward:-20.5, precision@10 : 0.22925531914893618, ndcg@10 : 0.2403946403536528\n",
    "Model: 18500, reward:-10.0, precision@10 : 0.23776595744680867, ndcg@10 : 0.24907804654027624\n",
    "Model: 19000, reward:-10.0, precision@10 : 0.2324468085106385, ndcg@10 : 0.2411231555043367\n",
    "Model: 19500, reward:-31.0, precision@10 : 0.23989361702127668, ndcg@10 : 0.25053426476006946\n",
    "Model: 20000, reward:-24.0, precision@10 : 0.2500000000000001, ndcg@10 : 0.2583297908664055"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "RL_ActorCritic_DDPG_Movie_Recommendation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
